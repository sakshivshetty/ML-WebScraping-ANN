{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import pandas\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single forward slash for the directory's name because I do not use windows.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://karki23.github.io/Weather-Data/assignment.html'\n",
    "a=requests.get(url)\n",
    "r=BeautifulSoup(a.content, \"lxml\")\n",
    "cities=r.find_all('a')\n",
    "import csv\n",
    "file_name=\"dataset/\"+\"All_Cities.\"+\"csv\"\n",
    "f=open(file_name, \"w\", newline=\"\")\n",
    "writer=csv.writer(f)\n",
    "writer.writerow(['Date','Location','MinTemp','MaxTemp','Rainfall','Evaporation','Sunshine','WindGustDir','WindGustSpeed','WindDir9am','WindDir3pm','WindSpeed9am','WindSpeed3pm','Humidity9am','Humidity3pm','Pressure9am','Pressure3pm','Cloud9am\t','Cloud3pm','Temp9am','Temp3pm','RainToday','RISK_MM','RainTomorrow'])\n",
    "for x in range(len(cities)):\n",
    "    s=cities[x].get('href')[0:len(cities[x])-5:]    \n",
    "    new_url='https://karki23.github.io/Weather-Data/'+cities[x].get('href')\n",
    "    new_a=requests.get(new_url)\n",
    "    new_r=BeautifulSoup(new_a.content, \"lxml\")\n",
    "    row=new_r.find_all('tr')\n",
    "    row.pop(0) \n",
    "    writer=csv.writer(f)\n",
    "    for i in row:    \n",
    "        column=i.find_all('td')\n",
    "        new_column=[j.text for j in column]\n",
    "        writer.writerow(new_column)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sakshishetty/Desktop/Python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sakshishetty/Desktop/Python/dataset\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/sakshishetty/Desktop/Python/dataset\")  #CHANGE ACCORDING TO YOUR SYSTEM\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv('All_Cities.csv')      #File consisting of data of all 49 cities\n",
    "dataset = dataset.drop(columns =['Date','Location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(read the comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "dataset['RainToday']=encoder.fit_transform(dataset['RainToday'])\n",
    "I initially tried using this method for all the string data, but I got an error I wasn't able to fix, \n",
    "so I opted for the method below.\n",
    "'''\n",
    "\n",
    "dataset['WindGustDir'] = pandas.Categorical(dataset['WindGustDir'])\n",
    "dataset['WindGustDir'] = dataset.WindGustDir.cat.codes\n",
    "dataset['WindDir9am'] = pandas.Categorical(dataset['WindDir9am'])\n",
    "dataset['WindDir9am'] = dataset.WindDir9am.cat.codes\n",
    "dataset['WindDir3pm'] = pandas.Categorical(dataset['WindDir3pm'])\n",
    "dataset['WindDir3pm'] = dataset.WindDir3pm.cat.codes\n",
    "dataset['RainTomorrow'] = pandas.Categorical(dataset['RainTomorrow'])\n",
    "dataset['RainTomorrow'] = dataset.RainTomorrow.cat.codes\n",
    "dataset['RainToday'] = pandas.Categorical(dataset['RainToday'])\n",
    "dataset['RainToday'] = dataset.RainToday.cat.codes\n",
    "\n",
    "dataset[['WindGustDir','WindDir9am','WindDir3pm']] = dataset[['WindGustDir','WindDir9am','WindDir3pm']].astype(float)\n",
    "\n",
    "#to get rid of negative values\n",
    "import numpy as np\n",
    "dataset[['WindDir9am']] = np.where(dataset[['WindDir9am']]<0, 0, dataset[['WindDir9am']])\n",
    "dataset[['WindGustDir']] = np.where(dataset[['WindGustDir']]<0, 0, dataset[['WindGustDir']])\n",
    "dataset[['WindDir3pm']] = np.where(dataset[['WindDir3pm']]<0, 0, dataset[['WindDir3pm']])\n",
    "dataset[['RainToday']] = np.where(dataset[['RainToday']]<0, 0, dataset[['RainToday']])\n",
    "\n",
    "#filling the missing values with mean\n",
    "dataset.fillna(dataset.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset.drop(columns=['RainTomorrow'])\n",
    "t = dataset[['RainTomorrow']]\n",
    "xtrain=d[1: int(0.8*len(d))]\n",
    "ytrain=t[1:int(0.8*len(t))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=d[int((0.8*len(d))): ]\n",
    "ytest=t[int((0.8*len(d))): ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "n = d.shape[1]  #number of columns in training data\n",
    "\n",
    "model.add(Dense(250, activation='relu', input_shape=(n,)))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "#accuracy seems to vary vastly based on the usage of sigmoid or relu or softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "113753/113753 [==============================] - 4s 37us/step - loss: 0.7059 - acc: 0.7703\n",
      "Epoch 2/10\n",
      "113753/113753 [==============================] - 4s 35us/step - loss: 0.6931 - acc: 0.7703\n",
      "Epoch 3/10\n",
      "113753/113753 [==============================] - 4s 36us/step - loss: 0.6931 - acc: 0.7703\n",
      "Epoch 4/10\n",
      "113753/113753 [==============================] - 4s 37us/step - loss: 0.6931 - acc: 0.7703\n",
      "Epoch 5/10\n",
      "113753/113753 [==============================] - 4s 38us/step - loss: 0.6931 - acc: 0.7703\n",
      "Epoch 6/10\n",
      "113753/113753 [==============================] - 4s 37us/step - loss: 0.6931 - acc: 0.7703\n",
      "Epoch 7/10\n",
      "113753/113753 [==============================] - 4s 37us/step - loss: 0.6931 - acc: 0.7703: 0s - loss: 0.6931\n",
      "Epoch 8/10\n",
      "113753/113753 [==============================] - 4s 38us/step - loss: 0.6931 - acc: 0.7703\n",
      "Epoch 9/10\n",
      "113753/113753 [==============================] - 4s 38us/step - loss: 0.6931 - acc: 0.7703\n",
      "Epoch 10/10\n",
      "113753/113753 [==============================] - 4s 38us/step - loss: 0.6931 - acc: 0.7703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb32877128>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28439/28439 [==============================] - 0s 13us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.798059003481135\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
